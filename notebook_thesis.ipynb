{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #suppress warnings\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.io import arff\n",
    "from pyod.models.anogan import AnoGAN\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67edf4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        # start preprocessing \n",
    "        self.arff_data = arff.loadarff(path)\n",
    "        self.df = pd.DataFrame(self.arff_data[0])\n",
    "        #0 is outlier, 1 is normal data\n",
    "        self.df[\"outlier\"] = pd.factorize(self.df[\"outlier\"])[0]\n",
    "        #end preprocessing\n",
    "        \n",
    "        self.data_tensor = torch.tensor(self.df.to_numpy()).float()\n",
    "        self.data_numpy = self.df.to_numpy()\n",
    "        self.n = self.df.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_tensor)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data_tensor[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f7d4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./Resources/Datasets/Arrhythmia_withoutdupl_norm_02_v01.arff\"\n",
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "num_workers = 2\n",
    "batch_size = 128\n",
    "#number of used GPUs\n",
    "gpu = 0 \n",
    "\n",
    "usedDevice = torch.device(\"cpu\" if gpu == 0 else \"cuda\")\n",
    "dataset = CustomDataset(path)\n",
    "train_set, eval_set, test_set = torch.utils.data.random_split(dataset.data_numpy[:,:-1], [0.6,0.2,0.2]) #PFUSCH WEGEN NUMPY?\n",
    "#maybe data loader for each category?\n",
    "dataloader = DataLoader(dataset=dataset.data_tensor, batch_size = batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(test_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "731ccfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(prediction):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    idx = 0\n",
    "    for i in test_set.indices:\n",
    "        if dataset.data_numpy[i][-1] != prediction[idx]:\n",
    "            correct += 1\n",
    "        else: \n",
    "            wrong += 1\n",
    "        idx += 1\n",
    "\n",
    "    print(len(test_set))\n",
    "    print(\"Accuracy: \" + str(correct/len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogaal_model = MO_GAAL(contamination=0.05)\n",
    "mogaal_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mogaal_pred = mogaal_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(test_mogaal_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anogan_model = AnoGAN()\n",
    "anogan_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264558c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_anogan_pred = anogan_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(test_anogan_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5859f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_model = LOF()\n",
    "lof_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96297a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lof_pred = lof_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(test_lof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b74df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_model = GMM(n_components=1)\n",
    "gmm_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31c0e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gmm_pred = gmm_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(test_gmm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef8405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
