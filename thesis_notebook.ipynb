{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 09:15:41.228191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 09:15:41.794216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.anogan import AnoGAN\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData():\n",
    "    def __init__(self, path):\n",
    "        arff_data = arff.loadarff(path)\n",
    "        df = pd.DataFrame(arff_data[0])\n",
    "        df[\"outlier\"] = pd.factorize(df[\"outlier\"], sort=True)[0]\n",
    "        \n",
    "        self.data = df.iloc[:,:-2]\n",
    "        self.ground_truth = df.iloc[:,-1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "        \n",
    "def AUC(truth, decision):\n",
    "    print(\"AUC: \" + str(metrics.roc_auc_score(truth, decision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x7F2DB06BBBA0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 666\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prior, prior_labels), (test, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prior, prior_labels), (test, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "outlier = 9\n",
    "idx = prior_labels == outlier\n",
    "train = prior[idx].copy() / 255\n",
    "nsamples, nx, ny = np.shape(train)\n",
    "train = train.reshape(nsamples, nx*ny)\n",
    "    \n",
    "test_copy = test.copy() / 255\n",
    "nsamples, nx, ny = np.shape(test_copy)\n",
    "test_copy = test_copy.reshape(nsamples, nx*ny)\n",
    "    \n",
    "    \n",
    "ground_truth = test_labels.copy()\n",
    "ground_truth[ground_truth != outlier] = 0\n",
    "ground_truth[ground_truth == outlier] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 784)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train))\n",
    "print(np.shape(test_copy))\n",
    "print(np.shape(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      " 0.         0.00392157 0.01568627 0.         0.         0.\n",
      " 0.         0.00392157 0.00392157 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01176471 0.\n",
      " 0.14117647 0.53333333 0.49803922 0.24313725 0.21176471 0.\n",
      " 0.         0.         0.00392157 0.01176471 0.01568627 0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02352941 0.         0.4        0.8\n",
      " 0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.\n",
      " 0.         0.         0.         0.04705882 0.03921569 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      " 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      " 0.30196078 0.50980392 0.28235294 0.05882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00392157 0.         0.27058824\n",
      " 0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569\n",
      " 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804\n",
      " 0.6745098  0.25882353 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392\n",
      " 0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412\n",
      " 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      " 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      " 0.8745098  0.96078431 0.67843137 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.75686275\n",
      " 0.89411765 0.85490196 0.83529412 0.77647059 0.70588235 0.83137255\n",
      " 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118\n",
      " 0.79215686 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255\n",
      " 0.85490196 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196\n",
      " 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02352941 0.\n",
      " 0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      " 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      " 0.96078431 0.46666667 0.65490196 0.21960784 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01568627 0.         0.         0.21568627 0.9254902\n",
      " 0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412\n",
      " 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784\n",
      " 0.36078431 0.         0.         0.         0.00392157 0.01568627\n",
      " 0.02352941 0.02745098 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.92941176 0.88627451 0.85098039 0.8745098\n",
      " 0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098\n",
      " 0.89803922 0.84313725 0.85490196 1.         0.30196078 0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.24313725 0.56862745 0.8\n",
      " 0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      " 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      " 0.87843137 0.95686275 0.62352941 0.         0.         0.\n",
      " 0.         0.         0.07058824 0.17254902 0.32156863 0.41960784\n",
      " 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451\n",
      " 0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706\n",
      " 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333\n",
      " 0.84313725 0.         0.         0.22352941 0.73333333 0.81568627\n",
      " 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569\n",
      " 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275\n",
      " 0.80784314 0.8745098  1.         1.         0.86666667 0.91764706\n",
      " 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.\n",
      " 0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      " 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      " 0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      " 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      " 0.87058824 0.89411765 0.88235294 0.         0.38431373 0.91372549\n",
      " 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706\n",
      " 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804\n",
      " 0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353\n",
      " 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137\n",
      " 0.89803922 0.11372549 0.29411765 0.8        0.83137255 0.8\n",
      " 0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902\n",
      " 0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588\n",
      " 0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255\n",
      " 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451\n",
      " 0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      " 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      " 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      " 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      " 0.70980392 0.80392157 0.80784314 0.45098039 0.         0.47843137\n",
      " 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745\n",
      " 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941\n",
      " 0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961\n",
      " 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765\n",
      " 0.82352941 0.36078431 0.         0.         0.29019608 0.74117647\n",
      " 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392\n",
      " 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059\n",
      " 0.8        0.81960784 0.82352941 0.82352941 0.82745098 0.7372549\n",
      " 0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.\n",
      " 0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      " 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      " 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      " 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      " 0.38823529 0.22745098 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15686275\n",
      " 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrythmia_path = \"./Resources/Datasets/Arrhythmia_withoutdupl_norm_02_v01.arff\"\n",
    "wave_path = \"./Resources/Datasets/Waveform_withoutdupl_norm_v01.arff\"\n",
    "internet_ads_path = \"./Resources/Datasets/InternetAds_withoutdupl_norm_02_v01.arff\"\n",
    "\n",
    "dataset = CustomData(arrythmia_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogaal_model = MO_GAAL(lr_d=0.01, lr_g=0.01, stop_epochs=50)\n",
    "mogaal_model.fit(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_values = mogaal_model.decision_function(dataset.data)\n",
    "AUC(dataset.ground_truth, decision_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_model = LOF()\n",
    "lof_model.fit(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_values = lof_model.decision_function(dataset.data)\n",
    "AUC(dataset.ground_truth, decision_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNN()\n",
    "knn_model.fit(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_values = knn_model.decision_function(dataset.data)\n",
    "AUC(dataset.ground_truth, decision_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anogan_model = AnoGAN()\n",
    "anogan_model.fit(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_values = anogan_model.decision_function(dataset.data)\n",
    "AUC(dataset.ground_truth, decision_values)\n",
    "anogan_model.plot_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
